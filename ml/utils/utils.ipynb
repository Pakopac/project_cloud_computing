{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n",
    "import logging\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    \"\"\"\n",
    "        Get data from csv\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "    def get_data(self):\n",
    "        print(\" - - - fetch data: - - - \")\n",
    "        self.data = pd.read_csv('../earthquakes.csv') \n",
    "        print( \" - - - data loaded - - - \\nFiles : earthquakes {}\".format(self.data.shape))\n",
    "    def get_process_data(self):\n",
    "        self.get_data()\n",
    "        print(\" - - - data processed - - - \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - - - fetch data: - - - \n",
      " - - - data loaded - - - \n",
      "Files : earthquakes (23412, 21)\n",
      " - - - data processed - - - \n"
     ]
    }
   ],
   "source": [
    "data = DataHandler()\n",
    "data.get_process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureRecipe(DataHandler):\n",
    "    \"\"\"\n",
    "    Feature processing class\n",
    "    \"\"\"\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        self.data = data\n",
    "        self.category = None\n",
    "        self.discrete_variable = None\n",
    "        self.continous_variable = None\n",
    "        \n",
    "    #Useless feature\n",
    "    def drop_useless(self):\n",
    "        \"\"\"\n",
    "        Drop useless column\n",
    "        \"\"\"\n",
    "\n",
    "        def drop_specific_col(self):\n",
    "            dropped_sepcific_col = []\n",
    "            dropped_sepcific_col.append('ID')\n",
    "            dropped_sepcific_col.append('Location Source')\n",
    "            dropped_sepcific_col.append('Magnitude Source')\n",
    "            dropped_sepcific_col.append('Magnitude Type')\n",
    "            return dropped_sepcific_col\n",
    "               \n",
    "        def drop_nan_col_100(self):\n",
    "            dropped_nan_col = []\n",
    "            for (columnName, columnData) in self.data.iteritems(): \n",
    "                if(self.data[columnName].isna().all() == True):\n",
    "                    dropped_nan_col.append(columnName)\n",
    "            print(\"{} feature have 100% NaN \".format(len(dropped_nan_col)))\n",
    "            return dropped_nan_col\n",
    "            \n",
    "        def drop_nan_col_25(df:pd.DataFrame, thresold: float):\n",
    "            bf=[]\n",
    "            for c in self.data.columns.to_list():\n",
    "                if self.data[c].isna().sum()/self.data.shape[0] > thresold:\n",
    "                    bf.append(c)\n",
    "            print(\"{} feature have more than {} NaN \".format(len(bf),thresold))\n",
    "            print('\\n\\n - - - features - - -  \\n {}'.format(bf))\n",
    "            return bf\n",
    "                \n",
    "        self.data = self.data.drop(drop_specific_col(self), axis=1)\n",
    "        self.data = self.data.drop(drop_nan_col_100(self), axis=1)\n",
    "        self.data = self.data.drop(drop_nan_col_25(self, 0.25), axis=1)\n",
    "        print(self.data)\n",
    "        print(\"- - - drop useless columns - - - \")\n",
    "        \n",
    "    def convert_timestamp(self):\n",
    "        \"\"\"\n",
    "        Convert date to timestamp\n",
    "        \"\"\"\n",
    "        timestamp = []\n",
    "        for d, t in zip(self.data['Date'], self.data['Time']):\n",
    "            try:\n",
    "                ts = datetime.datetime.strptime(d+' '+t, '%m/%d/%Y %H:%M:%S')\n",
    "                timestamp.append(time.mktime(ts.timetuple()))\n",
    "            except ValueError:\n",
    "                timestamp.append('ValueError')\n",
    "\n",
    "        timeStamp = pd.Series(timestamp)\n",
    "        self.data['Timestamp'] = timeStamp.values\n",
    "\n",
    "        self.data = self.data.drop(['Date', 'Time'], axis=1)\n",
    "        self.data = self.data[self.data.Timestamp != 'ValueError']\n",
    "        print(self.data.head())\n",
    "        print(\"- - - convert timestamp ---\")\n",
    "        \n",
    "    def encode_categorical_variable(self):\n",
    "        \"\"\"\n",
    "        Convert categoricals variables to numerics variables\n",
    "        \"\"\"\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(self.data['Type'])\n",
    "        self.data['Type'] = le.transform(self.data['Type'])\n",
    "\n",
    "        le.fit(self.data['Source'])\n",
    "        self.data['Source'] = le.transform(self.data['Source'])\n",
    "\n",
    "        le.fit(self.data['Status'])\n",
    "        self.data['Status'] = le.transform(self.data['Status'])\n",
    "        print(self.data)\n",
    "        print('- - - encoding variables - - -')\n",
    "        \n",
    "    def prepare_data(self):\n",
    "        \"\"\"\n",
    "        Wrap code above\n",
    "        \"\"\"\n",
    "        self.drop_useless()\n",
    "        self.convert_timestamp()\n",
    "        self.encode_categorical_variable()\n",
    "        print(\"- - - data processed - - -\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 feature have 100% NaN \n",
      "8 feature have more than 0.25 NaN \n",
      "\n",
      "\n",
      " - - - features - - -  \n",
      " ['Depth Error', 'Depth Seismic Stations', 'Magnitude Error', 'Magnitude Seismic Stations', 'Azimuthal Gap', 'Horizontal Distance', 'Horizontal Error', 'Root Mean Square']\n",
      "             Date      Time  Latitude  Longitude        Type   Depth  \\\n",
      "0      01/02/1965  13:44:18   19.2460   145.6160  Earthquake  131.60   \n",
      "1      01/04/1965  11:29:49    1.8630   127.3520  Earthquake   80.00   \n",
      "2      01/05/1965  18:05:58  -20.5790  -173.9720  Earthquake   20.00   \n",
      "3      01/08/1965  18:49:43  -59.0760   -23.5570  Earthquake   15.00   \n",
      "4      01/09/1965  13:32:50   11.9380   126.4270  Earthquake   15.00   \n",
      "...           ...       ...       ...        ...         ...     ...   \n",
      "23407  12/28/2016  08:22:12   38.3917  -118.8941  Earthquake   12.30   \n",
      "23408  12/28/2016  09:13:47   38.3777  -118.8957  Earthquake    8.80   \n",
      "23409  12/28/2016  12:38:51   36.9179   140.4262  Earthquake   10.00   \n",
      "23410  12/29/2016  22:30:19   -9.0283   118.6639  Earthquake   79.00   \n",
      "23411  12/30/2016  20:08:28   37.3973   141.4103  Earthquake   11.94   \n",
      "\n",
      "       Magnitude  Source     Status  \n",
      "0            6.0  ISCGEM  Automatic  \n",
      "1            5.8  ISCGEM  Automatic  \n",
      "2            6.2  ISCGEM  Automatic  \n",
      "3            5.8  ISCGEM  Automatic  \n",
      "4            5.8  ISCGEM  Automatic  \n",
      "...          ...     ...        ...  \n",
      "23407        5.6      NN   Reviewed  \n",
      "23408        5.5      NN   Reviewed  \n",
      "23409        5.9      US   Reviewed  \n",
      "23410        6.3      US   Reviewed  \n",
      "23411        5.5      US   Reviewed  \n",
      "\n",
      "[23412 rows x 9 columns]\n",
      "- - - drop useless columns - - - \n",
      "   Latitude  Longitude        Type  Depth  Magnitude  Source     Status  \\\n",
      "0    19.246    145.616  Earthquake  131.6        6.0  ISCGEM  Automatic   \n",
      "1     1.863    127.352  Earthquake   80.0        5.8  ISCGEM  Automatic   \n",
      "2   -20.579   -173.972  Earthquake   20.0        6.2  ISCGEM  Automatic   \n",
      "3   -59.076    -23.557  Earthquake   15.0        5.8  ISCGEM  Automatic   \n",
      "4    11.938    126.427  Earthquake   15.0        5.8  ISCGEM  Automatic   \n",
      "\n",
      "     Timestamp  \n",
      "0 -1.57631e+08  \n",
      "1 -1.57466e+08  \n",
      "2 -1.57356e+08  \n",
      "3 -1.57094e+08  \n",
      "4 -1.57026e+08  \n",
      "- - - convert timestamp ---\n",
      "       Latitude  Longitude  Type   Depth  Magnitude  Source  Status  \\\n",
      "0       19.2460   145.6160     0  131.60        6.0       4       0   \n",
      "1        1.8630   127.3520     0   80.00        5.8       4       0   \n",
      "2      -20.5790  -173.9720     0   20.00        6.2       4       0   \n",
      "3      -59.0760   -23.5570     0   15.00        5.8       4       0   \n",
      "4       11.9380   126.4270     0   15.00        5.8       4       0   \n",
      "...         ...        ...   ...     ...        ...     ...     ...   \n",
      "23407   38.3917  -118.8941     0   12.30        5.6       7       1   \n",
      "23408   38.3777  -118.8957     0    8.80        5.5       7       1   \n",
      "23409   36.9179   140.4262     0   10.00        5.9      11       1   \n",
      "23410   -9.0283   118.6639     0   79.00        6.3      11       1   \n",
      "23411   37.3973   141.4103     0   11.94        5.5      11       1   \n",
      "\n",
      "         Timestamp  \n",
      "0     -1.57631e+08  \n",
      "1     -1.57466e+08  \n",
      "2     -1.57356e+08  \n",
      "3     -1.57094e+08  \n",
      "4     -1.57026e+08  \n",
      "...            ...  \n",
      "23407  1.48291e+09  \n",
      "23408  1.48292e+09  \n",
      "23409  1.48293e+09  \n",
      "23410  1.48305e+09  \n",
      "23411  1.48313e+09  \n",
      "\n",
      "[23409 rows x 8 columns]\n",
      "- - - encoding variables - - -\n",
      "- - - data processed - - -\n"
     ]
    }
   ],
   "source": [
    "recipe = FeatureRecipe(data.data)\n",
    "recipe.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \"\"\"\n",
    "    Feature Extractor class\n",
    "    \"\"\"    \n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        \"\"\"\n",
    "            Input : pandas.DataFrame\n",
    "            Output : X_train, X_test, y_train, y_test according to sklearn.model_selection.train_test_split\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = data\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "    \n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "            drop useless column and set x and y\n",
    "        \"\"\"\n",
    "        x = self.data[[\"Latitude\", \"Longitude\", \"Timestamp\", \"Source\", \"Status\", \"Type\"]]\n",
    "        y= self.data[[\"Magnitude\", \"Depth\"]]\n",
    "        return x, y\n",
    "    \n",
    "    def split(self, size: float):\n",
    "        \"\"\"\n",
    "            train test split\n",
    "        \"\"\"\n",
    "        x, y = self.extract()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(x, y, random_state=42,test_size=size)\n",
    "        return self.X_train, self.X_test, self.y_train, self.y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Latitude  Longitude    Timestamp  Source  Status  Type\n",
       " 20003   -37.551    -73.465  1.26848e+09      11       1     0\n",
       " 18133    46.718    153.300  1.16363e+09      11       1     0\n",
       " 4158      3.745    128.131  2.17446e+08      11       1     0\n",
       " 18586   -14.177    -76.093  1.18733e+09      11       1     0\n",
       " 8248    -28.344   -176.488  5.32039e+08      11       1     0\n",
       " ...         ...        ...          ...     ...     ...   ...\n",
       " 11966   -10.233    113.569  7.71542e+08      11       1     0\n",
       " 21578    55.435   -135.018  1.35963e+09      11       1     0\n",
       " 5391     -6.495    129.367   3.1497e+08      11       1     0\n",
       " 860      -5.469    153.269 -5.88747e+07       4       0     0\n",
       " 15797    17.233   -101.250  1.01915e+09      11       1     0\n",
       " \n",
       " [21068 rows x 6 columns],\n",
       "        Latitude  Longitude    Timestamp  Source  Status  Type\n",
       " 13121   24.6020   122.2820  8.38672e+08      11       1     0\n",
       " 17921   -0.3900   123.1950  1.15118e+09      11       1     0\n",
       " 3419   -23.0220  -175.1120  1.65667e+08      11       1     0\n",
       " 20803   39.7090   143.2470  1.30621e+09      11       1     0\n",
       " 15057   -4.6230  -106.0440  9.72071e+08      11       1     0\n",
       " ...         ...        ...          ...     ...     ...   ...\n",
       " 21946  -19.2068  -172.3982  1.38342e+09      11       1     0\n",
       " 12225   -6.1340   103.9330  7.87922e+08      11       1     0\n",
       " 6439    -6.7130   102.9760  4.12066e+08      11       1     0\n",
       " 4575   -31.5560   -67.6950  2.49176e+08      11       1     0\n",
       " 13686  -22.4070   -68.4490  8.75488e+08      11       1     0\n",
       " \n",
       " [2341 rows x 6 columns],\n",
       "        Magnitude  Depth\n",
       " 20003        5.8   35.0\n",
       " 18133        5.5   10.0\n",
       " 4158         5.6   77.0\n",
       " 18586        5.6   19.8\n",
       " 8248         5.6   33.0\n",
       " ...          ...    ...\n",
       " 11966        5.8   33.0\n",
       " 21578        5.9   13.4\n",
       " 5391         5.6  209.0\n",
       " 860          5.7   30.0\n",
       " 15797        5.9   33.0\n",
       " \n",
       " [21068 rows x 2 columns],\n",
       "        Magnitude  Depth\n",
       " 13121        5.5   74.3\n",
       " 17921        6.3   26.0\n",
       " 3419         5.6   33.0\n",
       " 20803        5.8   16.0\n",
       " 15057        5.5   10.0\n",
       " ...          ...    ...\n",
       " 21946        5.7   10.0\n",
       " 12225        5.5   37.0\n",
       " 6439         6.1   29.0\n",
       " 4575         5.5   33.0\n",
       " 13686        5.6  106.8\n",
       " \n",
       " [2341 rows x 2 columns])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fextractor = FeatureExtractor(recipe.data)\n",
    "Fextractor.split(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelBuilder:\n",
    "    \"\"\"\n",
    "        Class for train and print results of ml model \n",
    "    \"\"\"\n",
    "    def __init__(self, model_path: str = None, save: bool = None):\n",
    "        self.model = None\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        self.model = RandomForestRegressor().fit(X, Y)\n",
    "        \n",
    "    def predict_test(self, X) -> np.ndarray:\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def save_model(self, path:str):\n",
    "        joblib.dump((self.model), '{}model.joblib'.format(path))\n",
    "        pass\n",
    "                    \n",
    "    def print_accuracy(self, X, Y):\n",
    "        return self.model.score(X, Y)\n",
    "        pass\n",
    "    \n",
    "    def load_model(self):\n",
    "        try:\n",
    "            joblib.load()\n",
    "            pass\n",
    "        except:\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = Fextractor.split(0.1)\n",
    "m = ModelBuilder() \n",
    "m.train(X_train, y_train)\n",
    "m.print_accuracy(X_test, y_test)\n",
    "m.predict_test(X_test)\n",
    "m.save_model('/home/lilian/project_cloud_computing/ml/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
